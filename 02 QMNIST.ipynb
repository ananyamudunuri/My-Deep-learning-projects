{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140747ed",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077370a7",
   "metadata": {},
   "source": [
    "### 2- In a new .ipynb notebook, reproduce the results utilizing the \"QMNIST\" dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2741d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2301e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as tran\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "088a1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran = tran.Compose([\n",
    "    tran.ToTensor(),  \n",
    "    tran.Normalize((0.1307,), (0.3081,))  #this is to Normalize with mean and std\n",
    "])\n",
    "\n",
    "FirstTrainData = torchvision.datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "FirstTestData = torchvision.datasets.QMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(FirstTrainData, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(FirstTestData, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3edc2b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_qmnist(data_loader, num_images=6):\n",
    "    # Get a batch of training images\n",
    "    data_iter = iter(data_loader)\n",
    "    images, labels = next(data_iter)  # Use next() to get the first batch\n",
    "    \n",
    "    # Plot the images in the batch\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 4))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {labels[i].item()}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some images from QMNIST\n",
    "visualize_qmnist(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d5e26a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the test dataset\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(FirstTestData), size=(1,)).item()\n",
    "    img, label = FirstTestData[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a9aa64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture for QMNIST\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer to first hidden layer\n",
    "        self.fc2 = nn.Linear(128, 64)       # First hidden layer to second hidden layer\n",
    "        self.fc3 = nn.Linear(64, 10)        # Second hidden layer to output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the 28x28 input images\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network for QMNIST\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62412f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa18e600",
   "metadata": {},
   "source": [
    "### 3- Report on the results in terms of prediction accuracy on the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc9de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6720db5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.7507481563091278\n",
      "Epoch 1, Batch 200, Loss: 0.35701928436756136\n",
      "Epoch 1, Batch 300, Loss: 0.2656426803022623\n",
      "Epoch 1, Batch 400, Loss: 0.24471366576850415\n",
      "Epoch 1, Batch 500, Loss: 0.22475007466971875\n",
      "Epoch 1, Batch 600, Loss: 0.191103161200881\n",
      "Epoch 1, Batch 700, Loss: 0.18328881192952395\n",
      "Epoch 1, Batch 800, Loss: 0.16517075017094612\n",
      "Epoch 1, Batch 900, Loss: 0.17252349521964788\n",
      "Epoch 2, Batch 100, Loss: 0.13790451930835843\n",
      "Epoch 2, Batch 200, Loss: 0.11818829074501991\n",
      "Epoch 2, Batch 300, Loss: 0.12692921413108707\n",
      "Epoch 2, Batch 400, Loss: 0.1275392660871148\n",
      "Epoch 2, Batch 500, Loss: 0.12683207508176564\n",
      "Epoch 2, Batch 600, Loss: 0.12950636815279723\n",
      "Epoch 2, Batch 700, Loss: 0.11478969346731902\n",
      "Epoch 2, Batch 800, Loss: 0.10829249026253819\n",
      "Epoch 2, Batch 900, Loss: 0.11880509339272977\n",
      "Epoch 3, Batch 100, Loss: 0.08524348329752683\n",
      "Epoch 3, Batch 200, Loss: 0.09210634500719607\n",
      "Epoch 3, Batch 300, Loss: 0.07535734883509576\n",
      "Epoch 3, Batch 400, Loss: 0.08805174465756864\n",
      "Epoch 3, Batch 500, Loss: 0.07490807982161642\n",
      "Epoch 3, Batch 600, Loss: 0.09711979539599269\n",
      "Epoch 3, Batch 700, Loss: 0.08628814595751465\n",
      "Epoch 3, Batch 800, Loss: 0.08615363153629005\n",
      "Epoch 3, Batch 900, Loss: 0.0848694306332618\n",
      "Epoch 4, Batch 100, Loss: 0.05796943424735218\n",
      "Epoch 4, Batch 200, Loss: 0.0622593380138278\n",
      "Epoch 4, Batch 300, Loss: 0.07253010226413607\n",
      "Epoch 4, Batch 400, Loss: 0.06549623951548711\n",
      "Epoch 4, Batch 500, Loss: 0.062316255695186555\n",
      "Epoch 4, Batch 600, Loss: 0.06763298145961016\n",
      "Epoch 4, Batch 700, Loss: 0.06601908314507454\n",
      "Epoch 4, Batch 800, Loss: 0.06491050352342427\n",
      "Epoch 4, Batch 900, Loss: 0.07130801762454211\n",
      "Epoch 5, Batch 100, Loss: 0.05181522408965975\n",
      "Epoch 5, Batch 200, Loss: 0.04722415617667139\n",
      "Epoch 5, Batch 300, Loss: 0.04473552920622751\n",
      "Epoch 5, Batch 400, Loss: 0.05445089863147587\n",
      "Epoch 5, Batch 500, Loss: 0.052289472240954635\n",
      "Epoch 5, Batch 600, Loss: 0.05360468192724511\n",
      "Epoch 5, Batch 700, Loss: 0.060654490098822865\n",
      "Epoch 5, Batch 800, Loss: 0.05808077388908714\n",
      "Epoch 5, Batch 900, Loss: 0.05864918940234929\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the neural network on the QMNIST dataset\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e659740b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e831147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 96.86%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f8e676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 96.86%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Convert predictions to numpy and store them\n",
    "        predictions.extend(predicted.cpu().numpy())  # Move tensor to CPU before converting to numpy\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d111061d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one test image and its label\n",
    "image, label = images[1], labels[1]\n",
    "\n",
    "# Reshape the image tensor to a 28x28 shape\n",
    "image = image.view(28, 28)\n",
    "\n",
    "# Convert the image tensor to a numpy array for visualization\n",
    "image_numpy = image.cpu().numpy()  # Ensure the tensor is moved to CPU before converting to numpy\n",
    "\n",
    "# Show the image\n",
    "plt.imshow(image_numpy, cmap='gray')\n",
    "plt.title(f'Predicted Label: {predictions[1]}, Actual Label: {label.item()}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f92b02",
   "metadata": {},
   "source": [
    "showing wrong prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ee84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc1a74f2",
   "metadata": {},
   "source": [
    "### 4- Choose one of the proposed modifications below\n",
    "\n",
    "#### Add another Dense layer of 128 nodes\n",
    "\n",
    "Hypothesize how it would change the performance results:\n",
    "This will help in increasing the models capacity to basicaaly differenciate complex tasks like telling the difference bewteen similar looking numbers. This will help in increasing the learning ability of the model to detect the complex features. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "400924cb",
   "metadata": {},
   "source": [
    " Adding Another Dense Layer of 128 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30811b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load the QMNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with mean and std\n",
    "])\n",
    "\n",
    "train_dataset = datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281db643",
   "metadata": {},
   "source": [
    "### 5- Modify the model based on the chosen method and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98ab2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6e9ed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the new model modelnew architecture to basically verify the modification  ModifiedMLP(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ModifiedMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128) \n",
    "        self.fc2 = nn.Linear(128, 128)      #  Adding Another Dense Layer of 128 Nodes\n",
    "        self.fc3 = nn.Linear(128, 64)       \n",
    "        self.fc4 = nn.Linear(64, 10)       \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)             \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))         \n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "modelnew = ModifiedMLP()\n",
    "\n",
    "print('This is the new model ''modelnew'' architecture to basically verify the modification ',modelnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c512005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.8251295740902423\n",
      "Epoch 1, Batch 200, Loss: 0.3348378924280405\n",
      "Epoch 1, Batch 300, Loss: 0.274042282551527\n",
      "Epoch 1, Batch 400, Loss: 0.22782042756676674\n",
      "Epoch 1, Batch 500, Loss: 0.22089141853153704\n",
      "Epoch 1, Batch 600, Loss: 0.20117520965635777\n",
      "Epoch 1, Batch 700, Loss: 0.18137603543698788\n",
      "Epoch 1, Batch 800, Loss: 0.16463984113186597\n",
      "Epoch 1, Batch 900, Loss: 0.15064507331699134\n",
      "Epoch 2, Batch 100, Loss: 0.12490918565541506\n",
      "Epoch 2, Batch 200, Loss: 0.12942522438243032\n",
      "Epoch 2, Batch 300, Loss: 0.12863109990023078\n",
      "Epoch 2, Batch 400, Loss: 0.09966310484334827\n",
      "Epoch 2, Batch 500, Loss: 0.11785555928014219\n",
      "Epoch 2, Batch 600, Loss: 0.11993815014138817\n",
      "Epoch 2, Batch 700, Loss: 0.10499951167032123\n",
      "Epoch 2, Batch 800, Loss: 0.11505110783502459\n",
      "Epoch 2, Batch 900, Loss: 0.10733258286491036\n",
      "Epoch 3, Batch 100, Loss: 0.09229339812882245\n",
      "Epoch 3, Batch 200, Loss: 0.09384526588022708\n",
      "Epoch 3, Batch 300, Loss: 0.07793211231008172\n",
      "Epoch 3, Batch 400, Loss: 0.07672286401037126\n",
      "Epoch 3, Batch 500, Loss: 0.0776977655198425\n",
      "Epoch 3, Batch 600, Loss: 0.07588340396992863\n",
      "Epoch 3, Batch 700, Loss: 0.0883267694246024\n",
      "Epoch 3, Batch 800, Loss: 0.07842905812431127\n",
      "Epoch 3, Batch 900, Loss: 0.08023829687852413\n",
      "Epoch 4, Batch 100, Loss: 0.0653430049191229\n",
      "Epoch 4, Batch 200, Loss: 0.060048032598569986\n",
      "Epoch 4, Batch 300, Loss: 0.0714939043438062\n",
      "Epoch 4, Batch 400, Loss: 0.06371777309570462\n",
      "Epoch 4, Batch 500, Loss: 0.07547089709900319\n",
      "Epoch 4, Batch 600, Loss: 0.06694594445405527\n",
      "Epoch 4, Batch 700, Loss: 0.05988406527787447\n",
      "Epoch 4, Batch 800, Loss: 0.060020386106334624\n",
      "Epoch 4, Batch 900, Loss: 0.05649244328029454\n",
      "Epoch 5, Batch 100, Loss: 0.038714320482686165\n",
      "Epoch 5, Batch 200, Loss: 0.0428441590606235\n",
      "Epoch 5, Batch 300, Loss: 0.04909959264332429\n",
      "Epoch 5, Batch 400, Loss: 0.051859609161037955\n",
      "Epoch 5, Batch 500, Loss: 0.06179362507071346\n",
      "Epoch 5, Batch 600, Loss: 0.05076436744537204\n",
      "Epoch 5, Batch 700, Loss: 0.04772215963806957\n",
      "Epoch 5, Batch 800, Loss: 0.05485349589725956\n",
      "Epoch 5, Batch 900, Loss: 0.06018689589109272\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the modified model\n",
    "modelnew = ModifiedMLP()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(modelnew.parameters(), lr=0.001)\n",
    "\n",
    "# Train the modified neural network\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    modelnew.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = modelnew(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8fa95d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set of the modified model: 97.18%\n"
     ]
    }
   ],
   "source": [
    "# Load the QMNIST test dataset\n",
    "test_dataset = datasets.QMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Evaluate the modified model on the QMNIST test dataset\n",
    "modelnew.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = modelnew(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracyofnewmodel = 100 * correct / total\n",
    "print(f'Accuracy on the test set of the modified model: {accuracyofnewmodel:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f37ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59419d06",
   "metadata": {},
   "source": [
    "### 6- Report on the results of the modified model and if it matches your hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640ddb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8ef35306",
   "metadata": {},
   "source": [
    "The model accuracy has increased to 97.18% from 96.86%. This proves the hypothesis of  Adding Another Dense Layer of 128 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d110a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "542c9f7b",
   "metadata": {},
   "source": [
    "### 7- Experiment with different optimizers, loss functions, dropout, and activation functions, and observe the change in performance as you tune these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4418f938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4de3da73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD - Epoch 1, Batch 100, Loss: 0.00827553087263368\n",
      "SGD - Epoch 1, Batch 200, Loss: 0.003345763402171542\n",
      "SGD - Epoch 1, Batch 300, Loss: 0.006717359465837945\n",
      "SGD - Epoch 1, Batch 400, Loss: 0.005036717600762586\n",
      "SGD - Epoch 1, Batch 500, Loss: 0.00455007920742446\n",
      "SGD - Epoch 1, Batch 600, Loss: 0.005478059608631156\n",
      "SGD - Epoch 1, Batch 700, Loss: 0.0019452117056880526\n",
      "SGD - Epoch 1, Batch 800, Loss: 0.00527936599871964\n",
      "SGD - Epoch 1, Batch 900, Loss: 0.0026613482243919863\n",
      "SGD - Epoch 2, Batch 100, Loss: 0.0009039496556306403\n",
      "SGD - Epoch 2, Batch 200, Loss: 0.0009938725729352882\n",
      "SGD - Epoch 2, Batch 300, Loss: 0.00068138420518153\n",
      "SGD - Epoch 2, Batch 400, Loss: 0.0008513239377407444\n",
      "SGD - Epoch 2, Batch 500, Loss: 0.0010845827538287266\n",
      "SGD - Epoch 2, Batch 600, Loss: 0.0014164898623653243\n",
      "SGD - Epoch 2, Batch 700, Loss: 0.0020122620853180707\n",
      "SGD - Epoch 2, Batch 800, Loss: 0.001256524486498165\n",
      "SGD - Epoch 2, Batch 900, Loss: 0.0009014186360127496\n",
      "SGD - Epoch 3, Batch 100, Loss: 0.0004465009275418197\n",
      "SGD - Epoch 3, Batch 200, Loss: 0.0005642790959018384\n",
      "SGD - Epoch 3, Batch 300, Loss: 0.0002938516083492004\n",
      "SGD - Epoch 3, Batch 400, Loss: 0.0003334594728846696\n",
      "SGD - Epoch 3, Batch 500, Loss: 0.00039289601919108465\n",
      "SGD - Epoch 3, Batch 600, Loss: 0.0005473478130693366\n",
      "SGD - Epoch 3, Batch 700, Loss: 0.0002989359827461158\n",
      "SGD - Epoch 3, Batch 800, Loss: 0.00042804311026088725\n",
      "SGD - Epoch 3, Batch 900, Loss: 0.0003753582043381698\n",
      "SGD - Epoch 4, Batch 100, Loss: 0.0003084266784404122\n",
      "SGD - Epoch 4, Batch 200, Loss: 0.00022714368835806908\n",
      "SGD - Epoch 4, Batch 300, Loss: 0.000370029031400918\n",
      "SGD - Epoch 4, Batch 400, Loss: 0.00029674864831008563\n",
      "SGD - Epoch 4, Batch 500, Loss: 0.00047569716355340576\n",
      "SGD - Epoch 4, Batch 600, Loss: 0.00026072357961993476\n",
      "SGD - Epoch 4, Batch 700, Loss: 0.0001901197543742228\n",
      "SGD - Epoch 4, Batch 800, Loss: 0.00024603262415297424\n",
      "SGD - Epoch 4, Batch 900, Loss: 0.00035711778867700164\n",
      "SGD - Epoch 5, Batch 100, Loss: 0.0001566283055092299\n",
      "SGD - Epoch 5, Batch 200, Loss: 0.0001450729591456934\n",
      "SGD - Epoch 5, Batch 300, Loss: 0.00030658736359100657\n",
      "SGD - Epoch 5, Batch 400, Loss: 0.00025890328777165904\n",
      "SGD - Epoch 5, Batch 500, Loss: 0.00017668515567066832\n",
      "SGD - Epoch 5, Batch 600, Loss: 0.00021105000750708312\n",
      "SGD - Epoch 5, Batch 700, Loss: 0.00016972394916976442\n",
      "SGD - Epoch 5, Batch 800, Loss: 0.00021199296997707507\n",
      "SGD - Epoch 5, Batch 900, Loss: 0.00035576769372980266\n",
      "Finished Training with SGD Optimizer\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "modelnew = ModifiedMLP()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'SGD - Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training with SGD Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2681497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set after SGD Optimizer: 98.09%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "modelnew.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set after SGD Optimizer: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71ed5dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSprop - Epoch 1, Batch 100, Loss: 0.057594943838269616\n",
      "RMSprop - Epoch 1, Batch 200, Loss: 0.020604122808971965\n",
      "RMSprop - Epoch 1, Batch 300, Loss: 0.01782489703241879\n",
      "RMSprop - Epoch 1, Batch 400, Loss: 0.013128173333633412\n",
      "RMSprop - Epoch 1, Batch 500, Loss: 0.01425962608232794\n",
      "RMSprop - Epoch 1, Batch 600, Loss: 0.02133756498782077\n",
      "RMSprop - Epoch 1, Batch 700, Loss: 0.016774093498111427\n",
      "RMSprop - Epoch 1, Batch 800, Loss: 0.015003449729684917\n",
      "RMSprop - Epoch 1, Batch 900, Loss: 0.017120502127845612\n",
      "RMSprop - Epoch 2, Batch 100, Loss: 0.008635762034533628\n",
      "RMSprop - Epoch 2, Batch 200, Loss: 0.012071608847472817\n",
      "RMSprop - Epoch 2, Batch 300, Loss: 0.01376221705609396\n",
      "RMSprop - Epoch 2, Batch 400, Loss: 0.019168083770537123\n",
      "RMSprop - Epoch 2, Batch 500, Loss: 0.01649295761145254\n",
      "RMSprop - Epoch 2, Batch 600, Loss: 0.009796825609469125\n",
      "RMSprop - Epoch 2, Batch 700, Loss: 0.020924208516935893\n",
      "RMSprop - Epoch 2, Batch 800, Loss: 0.010947268318291207\n",
      "RMSprop - Epoch 2, Batch 900, Loss: 0.015124038062528483\n",
      "RMSprop - Epoch 3, Batch 100, Loss: 0.011529272977015807\n",
      "RMSprop - Epoch 3, Batch 200, Loss: 0.023269981544551684\n",
      "RMSprop - Epoch 3, Batch 300, Loss: 0.011681347123041802\n",
      "RMSprop - Epoch 3, Batch 400, Loss: 0.008731550210637665\n",
      "RMSprop - Epoch 3, Batch 500, Loss: 0.012516599979462058\n",
      "RMSprop - Epoch 3, Batch 600, Loss: 0.014596677933400314\n",
      "RMSprop - Epoch 3, Batch 700, Loss: 0.012390365731880024\n",
      "RMSprop - Epoch 3, Batch 800, Loss: 0.016699687461050418\n",
      "RMSprop - Epoch 3, Batch 900, Loss: 0.011163082720842965\n",
      "RMSprop - Epoch 4, Batch 100, Loss: 0.017744622627222383\n",
      "RMSprop - Epoch 4, Batch 200, Loss: 0.012481753829324588\n",
      "RMSprop - Epoch 4, Batch 300, Loss: 0.009409096457021064\n",
      "RMSprop - Epoch 4, Batch 400, Loss: 0.006676952314176674\n",
      "RMSprop - Epoch 4, Batch 500, Loss: 0.01805279737490082\n",
      "RMSprop - Epoch 4, Batch 600, Loss: 0.007969667706923929\n",
      "RMSprop - Epoch 4, Batch 700, Loss: 0.01305504034489786\n",
      "RMSprop - Epoch 4, Batch 800, Loss: 0.013602706044769092\n",
      "RMSprop - Epoch 4, Batch 900, Loss: 0.015398808652684011\n",
      "RMSprop - Epoch 5, Batch 100, Loss: 0.01676082106632066\n",
      "RMSprop - Epoch 5, Batch 200, Loss: 0.011813621806525135\n",
      "RMSprop - Epoch 5, Batch 300, Loss: 0.0055648170024667105\n",
      "RMSprop - Epoch 5, Batch 400, Loss: 0.012042537496618023\n",
      "RMSprop - Epoch 5, Batch 500, Loss: 0.013186861917429269\n",
      "RMSprop - Epoch 5, Batch 600, Loss: 0.00838601145083544\n",
      "RMSprop - Epoch 5, Batch 700, Loss: 0.008626127707022419\n",
      "RMSprop - Epoch 5, Batch 800, Loss: 0.01800523569802948\n",
      "RMSprop - Epoch 5, Batch 900, Loss: 0.020229992879289397\n",
      "Finished Training with RMSprop Optimizer\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "modelnew = ModifiedMLP()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'RMSprop - Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training with RMSprop Optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0af0f347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set after RMSprop Optimizer: 97.60%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "modelnew.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set after RMSprop Optimizer: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48591f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE - Epoch 1, Batch 100, Loss: 0.038404599316418174\n",
      "MSE - Epoch 1, Batch 200, Loss: 0.031155221071094273\n",
      "MSE - Epoch 1, Batch 300, Loss: 0.02792476464062929\n",
      "MSE - Epoch 1, Batch 400, Loss: 0.0257039082236588\n",
      "MSE - Epoch 1, Batch 500, Loss: 0.024577207565307617\n",
      "MSE - Epoch 1, Batch 600, Loss: 0.023963981401175262\n",
      "MSE - Epoch 1, Batch 700, Loss: 0.023158919624984266\n",
      "MSE - Epoch 1, Batch 800, Loss: 0.02333525810390711\n",
      "MSE - Epoch 1, Batch 900, Loss: 0.023113490771502255\n",
      "MSE - Epoch 2, Batch 100, Loss: 0.021593415718525646\n",
      "MSE - Epoch 2, Batch 200, Loss: 0.021962590143084527\n",
      "MSE - Epoch 2, Batch 300, Loss: 0.02212824461981654\n",
      "MSE - Epoch 2, Batch 400, Loss: 0.02232949098572135\n",
      "MSE - Epoch 2, Batch 500, Loss: 0.021880355896428227\n",
      "MSE - Epoch 2, Batch 600, Loss: 0.021763530168682335\n",
      "MSE - Epoch 2, Batch 700, Loss: 0.021714199809357525\n",
      "MSE - Epoch 2, Batch 800, Loss: 0.021575242346152664\n",
      "MSE - Epoch 2, Batch 900, Loss: 0.021576138949021696\n",
      "MSE - Epoch 3, Batch 100, Loss: 0.02139580650255084\n",
      "MSE - Epoch 3, Batch 200, Loss: 0.020782128246501087\n",
      "MSE - Epoch 3, Batch 300, Loss: 0.021063829995691775\n",
      "MSE - Epoch 3, Batch 400, Loss: 0.02142033581621945\n",
      "MSE - Epoch 3, Batch 500, Loss: 0.021668447041884066\n",
      "MSE - Epoch 3, Batch 600, Loss: 0.021382803777232767\n",
      "MSE - Epoch 3, Batch 700, Loss: 0.020654744049534202\n",
      "MSE - Epoch 3, Batch 800, Loss: 0.020977939087897537\n",
      "MSE - Epoch 3, Batch 900, Loss: 0.020668705236166717\n",
      "MSE - Epoch 4, Batch 100, Loss: 0.02073279842734337\n",
      "MSE - Epoch 4, Batch 200, Loss: 0.020136869931593537\n",
      "MSE - Epoch 4, Batch 300, Loss: 0.02048877694644034\n",
      "MSE - Epoch 4, Batch 400, Loss: 0.020548714781180023\n",
      "MSE - Epoch 4, Batch 500, Loss: 0.02055224260315299\n",
      "MSE - Epoch 4, Batch 600, Loss: 0.020821189880371092\n",
      "MSE - Epoch 4, Batch 700, Loss: 0.0202476738858968\n",
      "MSE - Epoch 4, Batch 800, Loss: 0.020481053069233895\n",
      "MSE - Epoch 4, Batch 900, Loss: 0.02100079208612442\n",
      "MSE - Epoch 5, Batch 100, Loss: 0.020822753636166452\n",
      "MSE - Epoch 5, Batch 200, Loss: 0.020079285074025392\n",
      "MSE - Epoch 5, Batch 300, Loss: 0.020075525026768445\n",
      "MSE - Epoch 5, Batch 400, Loss: 0.020538243260234595\n",
      "MSE - Epoch 5, Batch 500, Loss: 0.020728807151317596\n",
      "MSE - Epoch 5, Batch 600, Loss: 0.020284754801541568\n",
      "MSE - Epoch 5, Batch 700, Loss: 0.02044005900621414\n",
      "MSE - Epoch 5, Batch 800, Loss: 0.020224137250334024\n",
      "MSE - Epoch 5, Batch 900, Loss: 0.019942795680835842\n",
      "Finished Training with MSE Loss\n",
      "Accuracy on the test set after MSE Loss: 79.34%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "modelnew = ModifiedMLP()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Convert labels to one-hot encoding for MSELoss\n",
    "        labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'MSE - Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training with MSE Loss')\n",
    "\n",
    "# Evaluate the model\n",
    "modelnew.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set after MSE Loss: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3018c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960da74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90ffb927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout - Epoch 1, Batch 100, Loss: 0.7072926089167595\n",
      "Dropout - Epoch 1, Batch 200, Loss: 0.49781426578760146\n",
      "Dropout - Epoch 1, Batch 300, Loss: 0.4183750095963478\n",
      "Dropout - Epoch 1, Batch 400, Loss: 0.35245897859334946\n",
      "Dropout - Epoch 1, Batch 500, Loss: 0.13769448800710962\n",
      "Dropout - Epoch 1, Batch 600, Loss: 0.040263966186903415\n",
      "Dropout - Epoch 1, Batch 700, Loss: 0.0375491330458317\n",
      "Dropout - Epoch 1, Batch 800, Loss: 0.039702816909994\n",
      "Dropout - Epoch 1, Batch 900, Loss: 0.02473827091176645\n",
      "Dropout - Epoch 2, Batch 100, Loss: 0.022990714357292746\n",
      "Dropout - Epoch 2, Batch 200, Loss: 0.014540646058158017\n",
      "Dropout - Epoch 2, Batch 300, Loss: 0.01914439535277779\n",
      "Dropout - Epoch 2, Batch 400, Loss: 0.02274506539448339\n",
      "Dropout - Epoch 2, Batch 500, Loss: 0.019542443085665582\n",
      "Dropout - Epoch 2, Batch 600, Loss: 0.02098520162900968\n",
      "Dropout - Epoch 2, Batch 700, Loss: 0.015290018461237197\n",
      "Dropout - Epoch 2, Batch 800, Loss: 0.022242374242923687\n",
      "Dropout - Epoch 2, Batch 900, Loss: 0.015352704340912168\n",
      "Dropout - Epoch 3, Batch 100, Loss: 0.01392030145649187\n",
      "Dropout - Epoch 3, Batch 200, Loss: 0.014557492474086758\n",
      "Dropout - Epoch 3, Batch 300, Loss: 0.014721824254736475\n",
      "Dropout - Epoch 3, Batch 400, Loss: 0.022921536511348678\n",
      "Dropout - Epoch 3, Batch 500, Loss: 0.020048538397568337\n",
      "Dropout - Epoch 3, Batch 600, Loss: 0.01182521374852513\n",
      "Dropout - Epoch 3, Batch 700, Loss: 0.012325040670475573\n",
      "Dropout - Epoch 3, Batch 800, Loss: 0.01808553594382829\n",
      "Dropout - Epoch 3, Batch 900, Loss: 0.017170663683700696\n",
      "Dropout - Epoch 4, Batch 100, Loss: 0.00991869127168684\n",
      "Dropout - Epoch 4, Batch 200, Loss: 0.005188428245974137\n",
      "Dropout - Epoch 4, Batch 300, Loss: 0.010120873113228299\n",
      "Dropout - Epoch 4, Batch 400, Loss: 0.010366732497741395\n",
      "Dropout - Epoch 4, Batch 500, Loss: 0.007486314935285918\n",
      "Dropout - Epoch 4, Batch 600, Loss: 0.009197751882129523\n",
      "Dropout - Epoch 4, Batch 700, Loss: 0.00650665284303841\n",
      "Dropout - Epoch 4, Batch 800, Loss: 0.013734433144618379\n",
      "Dropout - Epoch 4, Batch 900, Loss: 0.018078890870056055\n",
      "Dropout - Epoch 5, Batch 100, Loss: 0.010654108959533915\n",
      "Dropout - Epoch 5, Batch 200, Loss: 0.01591056048642713\n",
      "Dropout - Epoch 5, Batch 300, Loss: 0.011467074967840744\n",
      "Dropout - Epoch 5, Batch 400, Loss: 0.015792762497694637\n",
      "Dropout - Epoch 5, Batch 500, Loss: 0.01420678061684157\n",
      "Dropout - Epoch 5, Batch 600, Loss: 0.013305287473522186\n",
      "Dropout - Epoch 5, Batch 700, Loss: 0.01599866345697592\n",
      "Dropout - Epoch 5, Batch 800, Loss: 0.0156204596030193\n",
      "Dropout - Epoch 5, Batch 900, Loss: 0.009986052649874183\n",
      "Finished Training with Dropout\n",
      "Accuracy on the test set after dropout: 97.71%\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network with dropout\n",
    "class ModifiedMLPWithDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedMLPWithDropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)  # Apply dropout\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)  # Apply dropout\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the modified model with dropout\n",
    "modelnew = ModifiedMLPWithDropout()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model with dropout\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'Dropout - Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training with Dropout')\n",
    "\n",
    "# Evaluate the model\n",
    "modelnew.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set after dropout: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "809f3fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanh Activation - Epoch 1, Batch 100, Loss: 0.006607833274563291\n",
      "Tanh Activation - Epoch 1, Batch 200, Loss: 0.010786891182884801\n",
      "Tanh Activation - Epoch 1, Batch 300, Loss: 0.012239427611963265\n",
      "Tanh Activation - Epoch 1, Batch 400, Loss: 0.015639572989440645\n",
      "Tanh Activation - Epoch 1, Batch 500, Loss: 0.012946894485449435\n",
      "Tanh Activation - Epoch 1, Batch 600, Loss: 0.02393206746316537\n",
      "Tanh Activation - Epoch 1, Batch 700, Loss: 0.016757413547854868\n",
      "Tanh Activation - Epoch 1, Batch 800, Loss: 0.014801206123149769\n",
      "Tanh Activation - Epoch 1, Batch 900, Loss: 0.02163590364281845\n",
      "Tanh Activation - Epoch 2, Batch 100, Loss: 0.003916728422409505\n",
      "Tanh Activation - Epoch 2, Batch 200, Loss: 0.007371184928310868\n",
      "Tanh Activation - Epoch 2, Batch 300, Loss: 0.007247665797979153\n",
      "Tanh Activation - Epoch 2, Batch 400, Loss: 0.012824440564351107\n",
      "Tanh Activation - Epoch 2, Batch 500, Loss: 0.010672280179087466\n",
      "Tanh Activation - Epoch 2, Batch 600, Loss: 0.012828484264882718\n",
      "Tanh Activation - Epoch 2, Batch 700, Loss: 0.015817451835209793\n",
      "Tanh Activation - Epoch 2, Batch 800, Loss: 0.007590603002943226\n",
      "Tanh Activation - Epoch 2, Batch 900, Loss: 0.0060827045981704944\n",
      "Tanh Activation - Epoch 3, Batch 100, Loss: 0.013832093052951678\n",
      "Tanh Activation - Epoch 3, Batch 200, Loss: 0.009073090020045811\n",
      "Tanh Activation - Epoch 3, Batch 300, Loss: 0.004472377326546848\n",
      "Tanh Activation - Epoch 3, Batch 400, Loss: 0.002705085203813269\n",
      "Tanh Activation - Epoch 3, Batch 500, Loss: 0.002003888803631071\n",
      "Tanh Activation - Epoch 3, Batch 600, Loss: 0.004705610765875292\n",
      "Tanh Activation - Epoch 3, Batch 700, Loss: 0.01348536975355728\n",
      "Tanh Activation - Epoch 3, Batch 800, Loss: 0.018351936830313206\n",
      "Tanh Activation - Epoch 3, Batch 900, Loss: 0.025075546875177677\n",
      "Tanh Activation - Epoch 4, Batch 100, Loss: 0.019594538509081758\n",
      "Tanh Activation - Epoch 4, Batch 200, Loss: 0.008013627979105422\n",
      "Tanh Activation - Epoch 4, Batch 300, Loss: 0.009599096469137293\n",
      "Tanh Activation - Epoch 4, Batch 400, Loss: 0.008896686676907848\n",
      "Tanh Activation - Epoch 4, Batch 500, Loss: 0.009611236829714471\n",
      "Tanh Activation - Epoch 4, Batch 600, Loss: 0.008854588555059308\n",
      "Tanh Activation - Epoch 4, Batch 700, Loss: 0.007817259837365783\n",
      "Tanh Activation - Epoch 4, Batch 800, Loss: 0.01418845269866324\n",
      "Tanh Activation - Epoch 4, Batch 900, Loss: 0.016757265129890585\n",
      "Tanh Activation - Epoch 5, Batch 100, Loss: 0.010535899398723814\n",
      "Tanh Activation - Epoch 5, Batch 200, Loss: 0.01310487701429338\n",
      "Tanh Activation - Epoch 5, Batch 300, Loss: 0.011440133740069882\n",
      "Tanh Activation - Epoch 5, Batch 400, Loss: 0.010694535095861112\n",
      "Tanh Activation - Epoch 5, Batch 500, Loss: 0.010662817922368504\n",
      "Tanh Activation - Epoch 5, Batch 600, Loss: 0.024223654936704406\n",
      "Tanh Activation - Epoch 5, Batch 700, Loss: 0.010041291971101601\n",
      "Tanh Activation - Epoch 5, Batch 800, Loss: 0.012982483866591111\n",
      "Tanh Activation - Epoch 5, Batch 900, Loss: 0.006741052664701783\n",
      "Finished Training with Tanh Activation\n",
      "Accuracy on the test set after Tanh Activation: 97.72%\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network with tanh activation\n",
    "class ModifiedMLPWithTanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedMLPWithTanh, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.tanh(self.fc1(x))  # Using tanh activation\n",
    "        x = torch.tanh(self.fc2(x))  # Using tanh activation\n",
    "        x = torch.tanh(self.fc3(x))  # Using tanh activation\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model with tanh activation\n",
    "modelnew = ModifiedMLPWithTanh()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model with tanh activation\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'Tanh Activation - Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training with Tanh Activation')\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "modelnew.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set after Tanh Activation: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca8152cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 97.69%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "modelnew.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffb97c16",
   "metadata": {},
   "source": [
    "After using various different optimizers, loss functions, dropout, and activation functions , the accuracy have increased. SGD has the highest accuracy with approximately 98%. After  RMSprop Optimizer is 97.60%. This tell how effective learning rates and momentum tuning. However using MSE as the loss function did not improve that accuracy as much as the earlier indicating that these methods are better fit for classification tasks. Moreover , using activation functions generated higher accuracy as well like around 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e60eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
